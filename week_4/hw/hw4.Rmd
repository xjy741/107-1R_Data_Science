---
title: "texcloud"
author: "PoJenYo"
date: "20181010"
output: html_document
---
## 經濟新聞主要議題

這裡我們想要引用的資料是使用聚亨網的財經新聞資料來聚焦最近的新聞主題
首先先將套件引入，必清除資料庫

```{r}
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
```
引入資料
```{r}
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines, encoding="UTF-8-BOM")
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))
}
)
```
按照上次的課堂作業進行一些初步的整理
刪除
```{r}
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "月")
docs <- tm_map(docs, toSpace, "政府")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "月")
docs <- tm_map(docs, toSpace, "可能")
docs <- tm_map(docs, toSpace, "市場")
docs <- tm_map(docs, toSpace, "指出")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "認為")
docs <- tm_map(docs, toSpace, "可能")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "指出")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "已")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "因")
docs <- tm_map(docs, toSpace, "等")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "表示")
docs <- tm_map(docs, toSpace, "經濟")
docs <- tm_map(docs, toSpace, "預期")
docs <- tm_map(docs, toSpace, "公布")



docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)


mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))


```
將文字出現的頻率繪製成
```{r}

newdata <- freqFrame[order(-freqFrame$Freq),] 
newdata = head(newdata,n = 10)
barplot(newdata$Freq, names.arg = newdata$Var1)
```
```{r}
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "月")
docs <- tm_map(docs, toSpace, "政府")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "月")
docs <- tm_map(docs, toSpace, "可能")
docs <- tm_map(docs, toSpace, "市場")
docs <- tm_map(docs, toSpace, "指出")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "認為")
docs <- tm_map(docs, toSpace, "可能")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "指出")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "已")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "因")
docs <- tm_map(docs, toSpace, "等")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "表示")
docs <- tm_map(docs, toSpace, "經濟")
docs <- tm_map(docs, toSpace, "預期")
docs <- tm_map(docs, toSpace, "公布")
docs <- tm_map(docs, toSpace, "年")
docs <- tm_map(docs, toSpace, "他")


docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)


mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))


```
```{r}

newdata <- freqFrame[order(-freqFrame$Freq),] 
newdata = head(newdata,n = 10)
barplot(newdata$Freq, names.arg = newdata$Var1)
```
```{r}
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "月")
docs <- tm_map(docs, toSpace, "政府")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "月")
docs <- tm_map(docs, toSpace, "可能")
docs <- tm_map(docs, toSpace, "市場")
docs <- tm_map(docs, toSpace, "指出")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "認為")
docs <- tm_map(docs, toSpace, "可能")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "指出")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "已")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "因")
docs <- tm_map(docs, toSpace, "等")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "表示")
docs <- tm_map(docs, toSpace, "經濟")
docs <- tm_map(docs, toSpace, "預期")
docs <- tm_map(docs, toSpace, "公布")
docs <- tm_map(docs, toSpace, "年")
docs <- tm_map(docs, toSpace, "他")
docs <- tm_map(docs, toSpace, "但")
docs <- tm_map(docs, toSpace, "說")
docs <- tm_map(docs, toSpace, "至")
docs <- tm_map(docs, toSpace, "並")

docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)


mixseg = worker()
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))


```
再經過好幾輪之後，我們得到最後的結果。如下圖:

```{r}
wordcloud(freqFrame$Var1,freqFrame$Freq,
          scale=c(5,0.1),min.freq=20,max.words=150,
          random.order=TRUE, random.color=FALSE, 
          rot.per=.1, colors=brewer.pal(8, "Dark2"),
          ordered.colors=FALSE,use.r.layout=FALSE,
          fixed.asp=TRUE)
```
可以發現最近新聞主要聚焦在美國與中國貿易戰爭，所以這三個字很常出現。
最近因為美國的公債殖利率升高，還有新興國家的經濟不穩定，所以有風險這個字出現。
整體而言與最近現況相符合。

